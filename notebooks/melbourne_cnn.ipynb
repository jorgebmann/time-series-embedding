{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUJ569UbVdZ3",
        "outputId": "36b04dd2-b169-4bf1-c994-cab8f96797e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes:\n",
            "  X_train: (1194, 24)  y_train: (1194,)\n",
            "  X_valid: (1219, 24)  y_valid: (1219,)\n",
            "  X_test:  (1220, 24)  y_test:  (1220,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.io import arff\n",
        "\n",
        "DATA_DIR = 'datasets'\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def download_dataset(dataset_name, url):\n",
        "    zip_path    = os.path.join(DATA_DIR, f\"{dataset_name}.zip\")\n",
        "    extract_dir = os.path.join(DATA_DIR, dataset_name)\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zp:\n",
        "        zp.extractall(extract_dir)\n",
        "    os.remove(zip_path)\n",
        "    return extract_dir\n",
        "\n",
        "def load_arff_data(file_path):\n",
        "    raw, meta = arff.loadarff(file_path)\n",
        "    return pd.DataFrame(raw)\n",
        "\n",
        "def preprocess_data(train_df, test_df, valid_size=0.5, random_state=42):\n",
        "    # --- 1) Separate features & labels ---\n",
        "    X_train_df = train_df.drop(columns=['target'])\n",
        "    y_train_df = train_df['target'].astype(int)\n",
        "\n",
        "    X_temp_df  = test_df.drop(columns=['target'])\n",
        "    y_temp_df  = test_df['target'].astype(int)\n",
        "\n",
        "    # --- 2) Split temp into validation & test ---\n",
        "    X_valid_df, X_test_df, y_valid_df, y_test_df = train_test_split(\n",
        "        X_temp_df, y_temp_df,\n",
        "        test_size=valid_size,\n",
        "        random_state=random_state,\n",
        "        stratify=y_temp_df\n",
        "    )\n",
        "\n",
        "    # --- 3) Normalize all features (fit on train only) ---\n",
        "    scaler = StandardScaler().fit(X_train_df)\n",
        "    X_train_df = pd.DataFrame(\n",
        "        scaler.transform(X_train_df),\n",
        "        columns=X_train_df.columns,\n",
        "        index=X_train_df.index\n",
        "    )\n",
        "    X_valid_df = pd.DataFrame(\n",
        "        scaler.transform(X_valid_df),\n",
        "        columns=X_valid_df.columns,\n",
        "        index=X_valid_df.index\n",
        "    )\n",
        "    X_test_df = pd.DataFrame(\n",
        "        scaler.transform(X_test_df),\n",
        "        columns=X_test_df.columns,\n",
        "        index=X_test_df.index\n",
        "    )\n",
        "\n",
        "    # --- 4) Return six DataFrames/Series ---\n",
        "    return X_train_df, y_train_df, X_valid_df, y_valid_df, X_test_df, y_test_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_name = 'MelbournePedestrian'\n",
        "    url = 'https://timeseriesclassification.com/aeon-toolkit/MelbournePedestrian.zip'\n",
        "\n",
        "    path = download_dataset(dataset_name, url)\n",
        "    train_df = load_arff_data(os.path.join(path, f\"{dataset_name}_TRAIN.arff\"))\n",
        "    test_df  = load_arff_data(os.path.join(path, f\"{dataset_name}_TEST.arff\"))\n",
        "\n",
        "    X_train, y_train, X_valid, y_valid, X_test, y_test = preprocess_data(train_df, test_df)\n",
        "\n",
        "    print(\"Shapes:\")\n",
        "    print(\"  X_train:\", X_train.shape, \" y_train:\", y_train.shape)\n",
        "    print(\"  X_valid:\", X_valid.shape, \" y_valid:\", y_valid.shape)\n",
        "    print(\"  X_test: \", X_test.shape,  \" y_test: \", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hj1CNxODPFIz"
      },
      "outputs": [],
      "source": [
        "import time_series_embeddings1 as embd\n",
        "import clasfy_p1 as clasfy\n",
        "import clasfy_p2 as clasfy2\n",
        "import plot_umap as plt_um\n",
        "import pandas as pd\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z_lVrhrrPvYC"
      },
      "outputs": [],
      "source": [
        "#Performing scaling of the datasets\n",
        "train_sc, val_sc, test_sc = embd.std_scaling(X_train, X_valid, X_test)\n",
        "#without overlapping windows\n",
        "train_sct=train_sc\n",
        "test_sct=test_sc\n",
        "val_sct=val_sc\n",
        "ny_train=y_train\n",
        "ny_test=y_test\n",
        "ny_val=y_valid\n",
        "ny_train2=y_train-1\n",
        "ny_test2=y_test-1\n",
        "ny_val2=y_valid-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K_tkFTLTdvCR",
        "outputId": "57170f78-ca9d-492e-b5c8-3149c6195f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train_df shape: (1138, 24)\n",
            "y_train    shape: (1138,)\n",
            "x_val_df   shape: (1159, 24)\n",
            "y_val      shape: (1159,)\n",
            "x_test_df  shape: (1160, 24)\n",
            "y_test     shape: (1160,)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder_model\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"encoder_model\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m1,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m100,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m100,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,464\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,764</span> (811.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m207,764\u001b[0m (811.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,764</span> (811.58 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,764\u001b[0m (811.58 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"nnclr\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"nnclr\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ contrastive_augmenter           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ classification_augmenter        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_model (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">207,764</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ projection_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ linear_probe (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ contrastive_augmenter           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ classification_augmenter        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ encoder_model (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m207,764\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ projection_head (\u001b[38;5;33mSequential\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ linear_probe (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,539</span> (845.86 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m216,539\u001b[0m (845.86 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,539</span> (845.86 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m216,539\u001b[0m (845.86 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/200\n",
            "36/36 - 10s - 266ms/step - c_acc: 0.0600 - c_loss: 3.4301 - p_acc: 0.1007 - p_loss: nan - r_acc: 0.0836 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 2/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.0701 - c_loss: 3.4647 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.1157 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 3/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.0924 - c_loss: 3.2749 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.1480 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 4/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.1172 - c_loss: 3.2857 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.1534 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 5/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1271 - c_loss: 3.2569 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.1875 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 6/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1293 - c_loss: 3.0434 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2151 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 7/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1341 - c_loss: 2.8873 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2222 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 8/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1406 - c_loss: 3.0815 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2615 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 9/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1426 - c_loss: 3.0099 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2218 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 10/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1393 - c_loss: 2.9298 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2350 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 11/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1579 - c_loss: 3.1369 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2391 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 12/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1469 - c_loss: 2.7472 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2391 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 13/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1485 - c_loss: 2.8441 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2569 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 14/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1611 - c_loss: 2.6473 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.2711 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 15/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1793 - c_loss: 2.8033 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3045 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 16/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1836 - c_loss: 2.7750 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3275 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 17/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1867 - c_loss: 2.9776 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3227 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 18/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1847 - c_loss: 2.6397 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3385 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 19/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1987 - c_loss: 2.2783 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3403 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 20/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1939 - c_loss: 2.6836 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3333 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 21/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1993 - c_loss: 2.8679 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3572 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 22/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2085 - c_loss: 2.4722 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3526 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 23/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2303 - c_loss: 2.6024 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3570 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 24/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.1987 - c_loss: 2.5587 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3596 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 25/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2009 - c_loss: 2.5203 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3759 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 26/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2033 - c_loss: 2.5737 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3911 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 27/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2002 - c_loss: 2.2699 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3581 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 28/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2151 - c_loss: 2.6341 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3928 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 29/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2037 - c_loss: 2.5973 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3839 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 30/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2138 - c_loss: 2.3208 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3872 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 31/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2249 - c_loss: 2.4978 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4004 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 32/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2223 - c_loss: 2.8084 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3967 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 33/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2271 - c_loss: 2.2845 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3772 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 34/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2140 - c_loss: 2.4142 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3839 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 35/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2317 - c_loss: 2.4911 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3867 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 36/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2055 - c_loss: 2.5659 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3917 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 37/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2249 - c_loss: 2.2016 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3852 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 38/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2249 - c_loss: 2.4439 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4036 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 39/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2275 - c_loss: 2.4059 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4110 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 40/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2179 - c_loss: 2.4394 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3997 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 41/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2229 - c_loss: 2.3144 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4099 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 42/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2325 - c_loss: 2.2912 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4015 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 43/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2262 - c_loss: 2.6227 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3963 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 44/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2328 - c_loss: 2.2977 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.3989 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 45/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2338 - c_loss: 2.2354 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4000 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 46/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2249 - c_loss: 2.4267 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4062 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 47/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2295 - c_loss: 2.3678 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4143 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 48/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2325 - c_loss: 2.2123 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4282 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 49/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2275 - c_loss: 2.5118 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4102 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 50/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2214 - c_loss: 2.3202 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4206 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 51/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2358 - c_loss: 2.1026 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4375 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 52/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2229 - c_loss: 2.4653 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4110 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 53/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2380 - c_loss: 2.0458 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4234 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 54/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2434 - c_loss: 2.0988 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4184 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 55/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2404 - c_loss: 2.3758 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4325 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 56/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2393 - c_loss: 2.5416 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4191 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 57/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2459 - c_loss: 2.1465 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4225 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 58/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2312 - c_loss: 2.3801 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4184 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 59/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2343 - c_loss: 2.2354 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4269 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 60/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2314 - c_loss: 2.2690 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4490 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 61/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2402 - c_loss: 2.4600 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4497 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 62/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2402 - c_loss: 2.2010 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4462 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 63/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2513 - c_loss: 2.2733 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4538 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 64/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2402 - c_loss: 2.7495 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4323 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 65/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2419 - c_loss: 2.1796 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4295 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 66/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2469 - c_loss: 2.4637 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4484 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 67/200\n",
            "36/36 - 1s - 17ms/step - c_acc: 0.2441 - c_loss: 2.3160 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4475 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 68/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2395 - c_loss: 2.2456 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4342 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 69/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2450 - c_loss: 2.3451 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4373 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 70/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2478 - c_loss: 2.4836 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4425 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 71/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2537 - c_loss: 2.3216 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4399 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 72/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2544 - c_loss: 2.2733 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4455 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 73/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2421 - c_loss: 2.3348 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4379 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 74/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2400 - c_loss: 2.1325 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4327 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 75/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2480 - c_loss: 2.5055 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4577 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 76/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2428 - c_loss: 2.1470 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4395 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 77/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2463 - c_loss: 2.1436 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4533 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 78/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2511 - c_loss: 2.2542 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4457 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 79/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2504 - c_loss: 2.1368 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4484 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 80/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2463 - c_loss: 2.2526 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4579 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 81/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2456 - c_loss: 2.3478 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4559 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 82/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2362 - c_loss: 2.2711 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4577 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 83/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2552 - c_loss: 2.3118 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4507 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 84/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2465 - c_loss: 2.1851 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4434 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 85/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2659 - c_loss: 2.6388 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4592 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 86/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2522 - c_loss: 2.4106 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4466 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 87/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2476 - c_loss: 2.4897 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4455 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 88/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2459 - c_loss: 2.6297 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4599 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 89/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2509 - c_loss: 2.1981 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4568 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 90/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2450 - c_loss: 2.3695 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4540 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 91/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2552 - c_loss: 2.3515 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4772 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 92/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2594 - c_loss: 2.0072 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4677 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 93/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2541 - c_loss: 2.5682 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4510 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 94/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2469 - c_loss: 2.2285 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4588 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 95/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2500 - c_loss: 2.0689 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4451 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 96/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2483 - c_loss: 2.4653 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4588 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 97/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2544 - c_loss: 1.9816 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4755 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 98/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2672 - c_loss: 2.4545 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4627 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 99/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2520 - c_loss: 2.3423 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4622 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 100/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2417 - c_loss: 2.2862 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4538 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 101/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2552 - c_loss: 2.3613 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4679 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 102/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2561 - c_loss: 2.3492 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4614 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 103/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2714 - c_loss: 2.3265 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4748 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 104/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2594 - c_loss: 2.3291 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4646 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 105/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2607 - c_loss: 2.3992 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4724 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 106/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2572 - c_loss: 2.3169 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4698 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 107/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2618 - c_loss: 2.2947 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4724 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 108/200\n",
            "36/36 - 0s - 14ms/step - c_acc: 0.2734 - c_loss: 2.2524 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4601 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 109/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2679 - c_loss: 2.3462 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4816 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 110/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2618 - c_loss: 2.2538 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4833 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 111/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2659 - c_loss: 2.1318 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4750 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 112/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2723 - c_loss: 2.2726 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4859 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 113/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2679 - c_loss: 2.6170 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4677 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 114/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2576 - c_loss: 2.3832 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4711 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 115/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2500 - c_loss: 2.2260 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4635 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 116/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2624 - c_loss: 2.3470 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4657 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 117/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2662 - c_loss: 2.3621 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4588 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 118/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2712 - c_loss: 2.6492 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4523 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 119/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2723 - c_loss: 2.2089 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4588 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 120/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2688 - c_loss: 2.3067 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4698 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 121/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2642 - c_loss: 2.3469 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4670 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 122/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2675 - c_loss: 2.2572 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4727 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 123/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2563 - c_loss: 2.4589 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4824 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 124/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2773 - c_loss: 2.2209 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4729 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 125/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2672 - c_loss: 2.1754 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4731 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 126/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2740 - c_loss: 2.2628 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4759 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 127/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2688 - c_loss: 2.2153 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4746 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 128/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2662 - c_loss: 2.3770 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4852 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 129/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2644 - c_loss: 2.2523 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4594 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 130/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2607 - c_loss: 2.3936 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4661 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 131/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2834 - c_loss: 2.2471 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4781 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 132/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2557 - c_loss: 2.2787 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4729 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 133/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2467 - c_loss: 2.1528 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4622 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 134/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2714 - c_loss: 2.6379 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4742 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 135/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2638 - c_loss: 2.2709 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4651 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 136/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2648 - c_loss: 2.2141 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4694 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 137/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2703 - c_loss: 2.2797 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4677 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 138/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2550 - c_loss: 2.3080 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4646 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 139/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2662 - c_loss: 2.4277 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4798 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 140/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2677 - c_loss: 2.4408 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4826 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 141/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2790 - c_loss: 2.2518 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4792 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 142/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2747 - c_loss: 2.0874 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4774 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 143/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2614 - c_loss: 2.4589 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4707 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 144/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2651 - c_loss: 2.4608 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4707 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 145/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2664 - c_loss: 2.3039 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4683 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 146/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2734 - c_loss: 2.2363 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4809 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 147/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2808 - c_loss: 2.4363 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4711 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 148/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2585 - c_loss: 2.2649 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4683 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 149/200\n",
            "36/36 - 0s - 14ms/step - c_acc: 0.2731 - c_loss: 2.3963 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4661 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 150/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2515 - c_loss: 2.2513 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4724 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 151/200\n",
            "36/36 - 0s - 14ms/step - c_acc: 0.2579 - c_loss: 2.4535 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4631 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 152/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2758 - c_loss: 2.1884 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4707 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 153/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2688 - c_loss: 2.3511 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4698 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 154/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2557 - c_loss: 2.2967 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4688 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 155/200\n",
            "36/36 - 0s - 14ms/step - c_acc: 0.2703 - c_loss: 2.3525 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4629 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 156/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2659 - c_loss: 2.0818 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4703 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 157/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2738 - c_loss: 2.4879 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4744 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 158/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2681 - c_loss: 2.1856 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4633 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 159/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2716 - c_loss: 2.7781 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4631 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 160/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2677 - c_loss: 2.1544 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4727 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 161/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2817 - c_loss: 2.1902 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4755 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 162/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2688 - c_loss: 2.1353 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4683 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 163/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2629 - c_loss: 2.2617 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4742 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 164/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2679 - c_loss: 2.2635 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4612 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 165/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2779 - c_loss: 2.4671 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4776 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 166/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2701 - c_loss: 2.4529 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4748 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 167/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2745 - c_loss: 2.4428 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4718 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 168/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2727 - c_loss: 2.4617 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4816 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 169/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2736 - c_loss: 2.2277 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4818 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 170/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2651 - c_loss: 2.7794 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4703 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 171/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2648 - c_loss: 2.1680 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4779 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 172/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2692 - c_loss: 2.3740 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4865 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 173/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2758 - c_loss: 1.9581 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4959 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 174/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2762 - c_loss: 2.3836 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4768 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 175/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2760 - c_loss: 2.2347 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4807 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 176/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2723 - c_loss: 2.1171 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4705 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 177/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2814 - c_loss: 2.2663 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4833 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 178/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2775 - c_loss: 2.3678 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4911 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 179/200\n",
            "36/36 - 1s - 18ms/step - c_acc: 0.2793 - c_loss: 2.1312 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.5009 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 180/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2729 - c_loss: 2.0857 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4944 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 181/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2651 - c_loss: 2.5071 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4922 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 182/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2692 - c_loss: 2.0962 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4885 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 183/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2801 - c_loss: 2.2764 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4803 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 184/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2793 - c_loss: 2.1332 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4863 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 185/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2622 - c_loss: 2.0141 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4776 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 186/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2817 - c_loss: 1.9947 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4805 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 187/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2707 - c_loss: 2.1438 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4857 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 188/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2655 - c_loss: 2.5954 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4926 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 189/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2847 - c_loss: 2.3587 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4844 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 190/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2718 - c_loss: 2.3118 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4905 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 191/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2703 - c_loss: 2.0076 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4863 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 192/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2817 - c_loss: 2.3003 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4902 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 193/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2681 - c_loss: 2.3775 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4805 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 194/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2699 - c_loss: 2.3871 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4792 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 195/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2616 - c_loss: 1.9317 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4883 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 196/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2745 - c_loss: 2.1219 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4885 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 197/200\n",
            "36/36 - 1s - 15ms/step - c_acc: 0.2664 - c_loss: 2.5681 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4783 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 198/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2631 - c_loss: 2.1904 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4820 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 199/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2762 - c_loss: 2.3272 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4896 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 200/200\n",
            "36/36 - 1s - 14ms/step - c_acc: 0.2797 - c_loss: 2.1216 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.4816 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Preprocessing: 0.310s, Training: 115.929s, Inference: 0.190s\n"
          ]
        }
      ],
      "source": [
        "#nnclr_cnn embedding\n",
        "\n",
        "import nnclr_embdcnn as nn\n",
        "train_nn_cnn, val_nn_cnn, test_nn_cnn, train_time, inference_time = nn.nnclr_cnn_embedding_with_timing(train_sc, val_sc, test_sc,y_train-1,y_valid-1,y_test-1,64,7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z7F58h5TzgW9",
        "outputId": "821c25b7-9b79-4724-8e19-6b1a17fa68c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train_df shape: (1138, 24)\n",
            "y_train    shape: (1138,)\n",
            "x_val_df   shape: (1159, 24)\n",
            "y_val      shape: (1159,)\n",
            "x_test_df  shape: (1160, 24)\n",
            "y_test     shape: (1160,)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_encoder\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"transformer_encoder\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ transformer_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ input_projection (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sinusoidal_position_encoding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SinusoidalPositionEncoding</span>)    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pos_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_gap                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_projection (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ transformer_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ input_projection (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sinusoidal_position_encoding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSinusoidalPositionEncoding\u001b[0m)    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pos_dropout (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m83,200\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_block_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m83,200\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_gap                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_projection (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,688</span> (666.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m170,688\u001b[0m (666.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,688</span> (666.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m170,688\u001b[0m (666.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"nnclr\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"nnclr\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ contrastive_augmenter           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ classification_augmenter        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">170,688</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ projection_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ linear_probe (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ contrastive_augmenter           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ classification_augmenter        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m170,688\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ projection_head (\u001b[38;5;33mSequential\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ linear_probe (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,463</span> (701.03 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,463\u001b[0m (701.03 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,463</span> (701.03 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m179,463\u001b[0m (701.03 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/20\n",
            "36/36 - 20s - 542ms/step - c_acc: 0.0135 - c_loss: 3.9121 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0126 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 2/20\n",
            "36/36 - 1s - 27ms/step - c_acc: 0.0151 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0165 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 3/20\n",
            "36/36 - 1s - 27ms/step - c_acc: 0.0120 - c_loss: 3.9122 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0154 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 4/20\n",
            "36/36 - 1s - 26ms/step - c_acc: 0.0168 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0184 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 5/20\n",
            "36/36 - 1s - 26ms/step - c_acc: 0.0177 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0169 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 6/20\n",
            "36/36 - 1s - 35ms/step - c_acc: 0.0146 - c_loss: 3.9121 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0145 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 7/20\n",
            "36/36 - 1s - 40ms/step - c_acc: 0.0183 - c_loss: 3.9119 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0148 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 8/20\n",
            "36/36 - 2s - 63ms/step - c_acc: 0.0129 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0180 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 9/20\n",
            "36/36 - 1s - 31ms/step - c_acc: 0.0164 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0184 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 10/20\n",
            "36/36 - 1s - 30ms/step - c_acc: 0.0148 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0139 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 11/20\n",
            "36/36 - 1s - 27ms/step - c_acc: 0.0162 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0182 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 12/20\n",
            "36/36 - 1s - 27ms/step - c_acc: 0.0109 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0174 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 13/20\n",
            "36/36 - 1s - 27ms/step - c_acc: 0.0179 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0163 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 14/20\n",
            "36/36 - 1s - 30ms/step - c_acc: 0.0172 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0143 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 15/20\n",
            "36/36 - 1s - 26ms/step - c_acc: 0.0153 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0139 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 16/20\n",
            "36/36 - 1s - 27ms/step - c_acc: 0.0162 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0137 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 17/20\n",
            "36/36 - 1s - 41ms/step - c_acc: 0.0135 - c_loss: 3.9121 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0169 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 18/20\n",
            "36/36 - 1s - 34ms/step - c_acc: 0.0124 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0148 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 19/20\n",
            "36/36 - 1s - 31ms/step - c_acc: 0.0133 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0132 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Epoch 20/20\n",
            "36/36 - 1s - 30ms/step - c_acc: 0.0144 - c_loss: 3.9120 - p_acc: 0.1042 - p_loss: nan - r_acc: 0.0178 - val_p_acc: 0.1034 - val_p_loss: nan\n",
            "Preprocess: 0.397s  Train: 44.313s  Infer: 0.129s\n"
          ]
        }
      ],
      "source": [
        "#nnclr_lstm embedding\n",
        "#for the paper, 100 finetuning and training epochs were chosen, but here the example is done for 20 epochs\n",
        "# in a new cell, before you call anything from the module:\n",
        "import importlib\n",
        "import nnclr_embdcnn4 as nn          # your module as first imported\n",
        "importlib.reload(nn)\n",
        "\n",
        "train_nn_cnn, val_nn_cnn, test_nn_cnn, train_time, inference_time = nn.nnclr_cnn_embedding_with_timing(train_sc, val_sc, test_sc,y_train-1,y_valid-1,y_test-1,24,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBYrxidG-uDg",
        "outputId": "4d17f072-18eb-411c-f08c-cf3c985606c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 22:06:54,026] A new study created in memory with name: no-name-beb32cda-5701-4974-92c3-a3dd64755161\n",
            "[I 2025-07-07 22:06:54,078] Trial 0 finished with value: 0.10526315789473684 and parameters: {'C': 0.0008766103922919282, 'fit_intercept': True, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.4449383923749495}. Best is trial 0 with value: 0.10526315789473684.\n",
            "[I 2025-07-07 22:07:19,544] Trial 1 finished with value: 0.8593615185504746 and parameters: {'C': 2.814619695647055, 'fit_intercept': True, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.8281466941232535}. Best is trial 1 with value: 0.8593615185504746.\n",
            "[I 2025-07-07 22:07:23,908] Trial 2 finished with value: 0.7601380500431406 and parameters: {'C': 0.2521323307212541, 'fit_intercept': False, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.06689983548067069}. Best is trial 1 with value: 0.8593615185504746.\n",
            "[I 2025-07-07 22:07:24,568] Trial 3 finished with value: 0.1363244176013805 and parameters: {'C': 0.000865784887260439, 'fit_intercept': True, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.2890788221701436}. Best is trial 1 with value: 0.8593615185504746.\n",
            "[I 2025-07-07 22:07:46,024] Trial 4 finished with value: 0.8507333908541846 and parameters: {'C': 65.67503504984914, 'fit_intercept': False, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.18123690971598128}. Best is trial 1 with value: 0.8593615185504746.\n",
            "[I 2025-07-07 22:08:05,566] Trial 5 finished with value: 0.8455565142364107 and parameters: {'C': 5.790470516252801, 'fit_intercept': False, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.10366817391421523}. Best is trial 1 with value: 0.8593615185504746.\n",
            "[I 2025-07-07 22:08:07,126] Trial 6 finished with value: 0.2355478861087144 and parameters: {'C': 0.003407011564062777, 'fit_intercept': True, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.4369952300597595}. Best is trial 1 with value: 0.8593615185504746.\n",
            "[I 2025-07-07 22:08:07,165] Trial 7 finished with value: 0.10440034512510785 and parameters: {'C': 7.744773792994291e-10, 'fit_intercept': False, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.47161650585862536}. Best is trial 1 with value: 0.8593615185504746.\n",
            "[I 2025-07-07 22:08:07,197] Trial 8 finished with value: 0.10440034512510785 and parameters: {'C': 1.2646862863870897e-08, 'fit_intercept': False, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.8715705432407472}. Best is trial 1 with value: 0.8593615185504746.\n",
            "[I 2025-07-07 22:08:58,887] Trial 9 finished with value: 0.8783433994823123 and parameters: {'C': 129.0053562192251, 'fit_intercept': True, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.7120468969275761}. Best is trial 9 with value: 0.8783433994823123.\n",
            "[I 2025-07-07 22:08:58,920] Trial 10 finished with value: 0.10526315789473684 and parameters: {'C': 5.674515612802071e-07, 'fit_intercept': True, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.6807964024355022}. Best is trial 9 with value: 0.8783433994823123.\n",
            "[I 2025-07-07 22:09:50,586] Trial 11 finished with value: 0.8783433994823123 and parameters: {'C': 999.5882356277856, 'fit_intercept': True, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9332309267412628}. Best is trial 9 with value: 0.8783433994823123.\n",
            "[I 2025-07-07 22:10:42,877] Trial 12 finished with value: 0.8783433994823123 and parameters: {'C': 982.0460536742479, 'fit_intercept': True, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9793902312140353}. Best is trial 9 with value: 0.8783433994823123.\n"
          ]
        }
      ],
      "source": [
        "namem=\"melbourne-cnn\"\n",
        "\n",
        "best_params, best_score = clasfy.optimize_LOGRG(train_nn_cnn, val_nn_cnn, test_nn_cnn,ny_train, ny_val, ny_test,namem)\n",
        "print(best_params, best_score)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
